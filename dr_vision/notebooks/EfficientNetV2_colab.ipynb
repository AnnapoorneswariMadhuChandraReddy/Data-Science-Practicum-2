{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2926477-0d83-4f54-8eba-21d829ff567b",
   "metadata": {
    "id": "c2926477-0d83-4f54-8eba-21d829ff567b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EpUZIIduYiDn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EpUZIIduYiDn",
    "outputId": "2ae70be9-5712-4dbb-c145-3d3e405f04df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset unzipped into datasets/preprocessed/\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_path = \"/content/preprocessed.zip\"\n",
    "extract_path = \"datasets/preprocessed\"\n",
    "\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"Dataset unzipped into datasets/preprocessed/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c8e1e3-192d-4db9-909e-f942870aa855",
   "metadata": {},
   "source": [
    "##  EfficientNetV2 on Pre-processed  Fundus Images\n",
    "\n",
    "- We use built-in `EfficientNet_V2_S_Weights` transforms for inference-ready preprocessing.\n",
    "\n",
    "- We initialize an **EfficientNet-V2-S model pretrained on ImageNet** and modify the final classifier layer for **2 classes**:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e22c63-20d6-44b9-8c4d-ec66e6821671",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52e22c63-20d6-44b9-8c4d-ec66e6821671",
    "outputId": "759168a3-1dd2-4c80-e98c-a73686baacd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "\n",
    "# Dataset Paths\n",
    "train_dir = \"/content/datasets/preprocessed/preprocessed/train\"\n",
    "val_dir   = \"/content/datasets/preprocessed/preprocessed/val\"\n",
    "test_dir  = \"/content/datasets/preprocessed/preprocessed/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16738d06-694d-46ba-8fc5-fe1a747b68e1",
   "metadata": {
    "id": "16738d06-694d-46ba-8fc5-fe1a747b68e1"
   },
   "outputs": [],
   "source": [
    "# Transforms\n",
    "weights = EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "# Train transform with augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    preprocess\n",
    "])\n",
    "\n",
    "# Validation & Test transform\n",
    "val_test_transform = preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82566f08-315a-4bdd-9c7a-471cea2e5db9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82566f08-315a-4bdd-9c7a-471cea2e5db9",
    "outputId": "2d3260cc-cb89-44df-a577-a969af77f967"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset sizes:\n",
      "Train: 10122\n",
      "Val: 708\n",
      "Test: 712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Datasets & Dataloaders\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n",
    "val_dataset   = datasets.ImageFolder(val_dir, transform=val_test_transform)\n",
    "test_dataset  = datasets.ImageFolder(test_dir, transform=val_test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "print(\"Dataset sizes:\")\n",
    "print(\"Train:\", len(train_dataset))\n",
    "print(\"Val:\", len(val_dataset))\n",
    "print(\"Test:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dcb81f-dc64-4e21-aa1a-8bbcc826e245",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20dcb81f-dc64-4e21-aa1a-8bbcc826e245",
    "outputId": "88cb9a76-7fc4-423f-e7e5-563340b762f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82.7M/82.7M [00:00<00:00, 198MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Load EfficientNet-V2 Model\n",
    "model = efficientnet_v2_s(weights=weights)\n",
    "num_features = model.classifier[1].in_features\n",
    "model.classifier[1] = nn.Linear(num_features, 2)  # 2 classes\n",
    "\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4ac294-2b4f-49bd-815d-4095a08877bd",
   "metadata": {
    "id": "ee4ac294-2b4f-49bd-815d-4095a08877bd"
   },
   "outputs": [],
   "source": [
    "# Loss & Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71918dd-3478-46ec-99b5-c853a870f9e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d71918dd-3478-46ec-99b5-c853a870f9e5",
    "outputId": "d1e859db-8409-441e-bb38-46ebfa817cf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] | Loss: 0.1540 | Val Acc: 0.9718 | Time: 302.9s\n",
      "Saved new best model: 0.9717514124293786\n",
      "Epoch [2/10] | Loss: 0.0542 | Val Acc: 0.9732 | Time: 312.4s\n",
      "Saved new best model: 0.9731638418079096\n",
      "Epoch [3/10] | Loss: 0.0381 | Val Acc: 0.9746 | Time: 311.8s\n",
      "Saved new best model: 0.9745762711864406\n",
      "Epoch [4/10] | Loss: 0.0282 | Val Acc: 0.9802 | Time: 311.8s\n",
      "Saved new best model: 0.980225988700565\n",
      "Epoch [5/10] | Loss: 0.0233 | Val Acc: 0.9802 | Time: 311.2s\n",
      "Epoch [6/10] | Loss: 0.0123 | Val Acc: 0.9774 | Time: 312.2s\n",
      "Epoch [7/10] | Loss: 0.0201 | Val Acc: 0.9831 | Time: 311.8s\n",
      "Saved new best model: 0.9830508474576272\n",
      "Epoch [8/10] | Loss: 0.0213 | Val Acc: 0.9534 | Time: 311.1s\n",
      "Epoch [9/10] | Loss: 0.0147 | Val Acc: 0.9732 | Time: 311.4s\n",
      "Epoch [10/10] | Loss: 0.0176 | Val Acc: 0.9590 | Time: 312.4s\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "NUM_EPOCHS = 10\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "\n",
    "    #  Validation\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] | Loss: {avg_loss:.4f} | Val Acc: {val_acc:.4f} | Time: {time.time()-start_time:.1f}s\")\n",
    "\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_efficientnetv2.pth\")\n",
    "        print(\"Saved new best model:\", val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67d7435-bf43-4897-8f40-04f848460f19",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "###  Final Evaluation\n",
    "We evaluate the enhanced model on the **test dataset**, giving the final:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61aaeac-07ee-4bd8-b3fd-52b785a83f1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c61aaeac-07ee-4bd8-b3fd-52b785a83f1f",
    "outputId": "b5d2bfd9-66cf-451f-d729-12c3d7ba44d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TEST ACCURACY: 0.9775280898876404\n"
     ]
    }
   ],
   "source": [
    "# Test Accuracy\n",
    "model.load_state_dict(torch.load(\"best_efficientnetv2.pth\"))\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_acc = correct / total\n",
    "print(\" TEST ACCURACY:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LoGAJ8jToToM",
   "metadata": {
    "id": "LoGAJ8jToToM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DR-Vision Env",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MILQ3LeJOfIM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MILQ3LeJOfIM",
    "outputId": "b64281fc-dc7e-4ce1-b19a-330228adf74b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset unzipped into datasets/preprocessed/\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = \"/content/preprocessed.zip\"\n",
    "extract_path = \"datasets/preprocessed\"\n",
    "\n",
    "os.makedirs(extract_path, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(extract_path)\n",
    "\n",
    "print(\"Dataset unzipped into datasets/preprocessed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2510a184-5d89-4bef-aade-048d559198cc",
   "metadata": {
    "id": "2510a184-5d89-4bef-aade-048d559198cc"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Basic CNN using preprocessed images\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f656b7d-1793-490a-b258-40e498bdf3bb",
   "metadata": {
    "id": "6f656b7d-1793-490a-b258-40e498bdf3bb"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "IMG_SIZE = 224       # Preprocessed images are already 224x224\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 2\n",
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset class\n",
    "class DRDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        label_map = {\"No_DR\":0, \"DR\":1}\n",
    "\n",
    "        for label in os.listdir(root_dir):\n",
    "            if label not in label_map:\n",
    "                continue\n",
    "            label_dir = os.path.join(root_dir, label)\n",
    "            for img_file in os.listdir(label_dir):\n",
    "                self.images.append(os.path.join(label_dir, img_file))\n",
    "                self.labels.append(label_map[label])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Load preprocessed image directly\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f4f831-1638-436f-9fca-9ca3c2635ada",
   "metadata": {
    "id": "42f4f831-1638-436f-9fca-9ca3c2635ada"
   },
   "outputs": [],
   "source": [
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae6dfe6-e156-4379-9e96-b4e849be6198",
   "metadata": {
    "id": "aae6dfe6-e156-4379-9e96-b4e849be6198"
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dir = \"/content/datasets/preprocessed/preprocessed/train\"\n",
    "val_dir   = \"/content/datasets/preprocessed/preprocessed/val\"\n",
    "test_dir  = \"/content/datasets/preprocessed/preprocessed/test\"\n",
    "\n",
    "train_dataset = DRDataset(train_dir, transform=train_transform)\n",
    "val_dataset   = DRDataset(val_dir, transform=val_test_transform)\n",
    "test_dataset  = DRDataset(test_dir, transform=val_test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nzpNd_7JSFFu",
   "metadata": {
    "id": "nzpNd_7JSFFu"
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 56 * 56, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PYSRnDNrSVuv",
   "metadata": {
    "id": "PYSRnDNrSVuv"
   },
   "outputs": [],
   "source": [
    "# Instantiate model, loss, optimizer\n",
    "model = SimpleCNN(NUM_CLASSES).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jQ0K-LmMSZuL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jQ0K-LmMSZuL",
    "outputId": "745d9b3d-5f89-4af5-f777-0165f52a88a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] | Loss: 0.6405\n",
      "Validation Accuracy: 0.7980\n",
      " Saved new best model\n",
      "Epoch [2/10] | Loss: 0.4913\n",
      "Validation Accuracy: 0.8107\n",
      " Saved new best model\n",
      "Epoch [3/10] | Loss: 0.4551\n",
      "Validation Accuracy: 0.8136\n",
      " Saved new best model\n",
      "Epoch [4/10] | Loss: 0.4305\n",
      "Validation Accuracy: 0.8390\n",
      " Saved new best model\n",
      "Epoch [5/10] | Loss: 0.4043\n",
      "Validation Accuracy: 0.8079\n",
      "Epoch [6/10] | Loss: 0.3603\n",
      "Validation Accuracy: 0.7952\n",
      "Epoch [7/10] | Loss: 0.3301\n",
      "Validation Accuracy: 0.7698\n",
      "Epoch [8/10] | Loss: 0.2818\n",
      "Validation Accuracy: 0.8065\n",
      "Epoch [9/10] | Loss: 0.2330\n",
      "Validation Accuracy: 0.8729\n",
      " Saved new best model\n",
      "Epoch [10/10] | Loss: 0.2081\n",
      "Validation Accuracy: 0.8249\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # ---- Training ----\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] | Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_acc = correct / total\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    # ---- Save best model ----\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_cnn_preprocessed.pth\")\n",
    "        print(\" Saved new best model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k6eRatR9SeLd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k6eRatR9SeLd",
    "outputId": "6d3be07f-d015-4521-a49e-777ab8e2ab79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8553\n"
     ]
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "model.load_state_dict(torch.load(\"/content/best_cnn_preprocessed.pth\"))\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52f1a5f-1a4d-4a97-8d8d-4ba13fcc998a",
   "metadata": {
    "id": "c52f1a5f-1a4d-4a97-8d8d-4ba13fcc998a"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define a small CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),  # 224 -> 112\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),  # 112 -> 56\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),  # 56 -> 28\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),  # 28 -> 14\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256*14*14, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c602e1-eb75-42fc-bacf-1bea30482c83",
   "metadata": {
    "id": "11c602e1-eb75-42fc-bacf-1bea30482c83"
   },
   "outputs": [],
   "source": [
    "# Instantiate model, loss, optimizer\n",
    "model = SimpleCNN(NUM_CLASSES).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048d5357-e0c1-4401-9d90-267203a739f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "048d5357-e0c1-4401-9d90-267203a739f8",
    "outputId": "901b05da-dd92-43ca-fe37-f4d1b6661ea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10] | Loss: 0.5634\n",
      "Validation Accuracy: 0.8136\n",
      " Saved new best model\n",
      "Epoch [2/10] | Loss: 0.4259\n",
      "Validation Accuracy: 0.8121\n",
      "Epoch [3/10] | Loss: 0.3409\n",
      "Validation Accuracy: 0.8898\n",
      " Saved new best model\n",
      "Epoch [4/10] | Loss: 0.2772\n",
      "Validation Accuracy: 0.8983\n",
      " Saved new best model\n",
      "Epoch [5/10] | Loss: 0.2195\n",
      "Validation Accuracy: 0.8969\n",
      "Epoch [6/10] | Loss: 0.1830\n",
      "Validation Accuracy: 0.9280\n",
      " Saved new best model\n",
      "Epoch [7/10] | Loss: 0.1492\n",
      "Validation Accuracy: 0.9209\n",
      "Epoch [8/10] | Loss: 0.1300\n",
      "Validation Accuracy: 0.9068\n",
      "Epoch [9/10] | Loss: 0.1064\n",
      "Validation Accuracy: 0.9195\n",
      "Epoch [10/10] | Loss: 0.0910\n",
      "Validation Accuracy: 0.9237\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.0\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    #  Training \n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] | Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_acc = correct / total\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "    # Save best model \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_cnn_preprocessed2.pth\")\n",
    "        print(\" Saved new best model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f91c0b-fcf0-4c4b-b442-5adbbec8999a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93f91c0b-fcf0-4c4b-b442-5adbbec8999a",
    "outputId": "8b98b560-cc5d-46cf-bcb8-ee85d8d98376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9059\n"
     ]
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "model.load_state_dict(torch.load(\"/content/best_cnn_preprocessed2.pth\"))\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SsCxjdVvYMFQ",
   "metadata": {
    "id": "SsCxjdVvYMFQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
